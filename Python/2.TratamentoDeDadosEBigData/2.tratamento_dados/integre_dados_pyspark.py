# -*- coding: utf-8 -*-
"""integre_dados_pyspark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jhyuq63R__gDMl_yAcd4XBDIJvSsacWB
"""

!pip install pyspark

import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col,upper
from pyspark.sql.functions import to_date, date_format, unix_timestamp, from_unixtime, concat, lit

spark = SparkSession.builder.getOrCreate()

produtos = spark.read.csv('drive/MyDrive/Spark/Data/produtos.csv', header=True, inferSchema=True)
clientes = spark.read.csv('drive/MyDrive/Spark/Data/clientes.csv', header=True, inferSchema=True)
itens_pedidos = spark.read.csv('drive/MyDrive/Spark/Data/itens_pedido.csv', header=True, inferSchema=True)
pedidos = spark.read.csv('drive/MyDrive/Spark/Data/pedidos.csv', header=True, inferSchema=True)

produtos.show(5)
clientes.show(5)
itens_pedidos.show(5)
pedidos.show()

join_pedidos_clientes_df = pedidos.join(clientes,pedidos['id_cliente'] == clientes['id_cliente'], 'inner')
join_pedidos_clientes_df = pedidos.join(clientes, 'id_cliente')

join_pedidos_clientes_df.show(5)

join_itens_pedido_df = itens_pedidos.join(pedidos,'id_pedido').join(produtos,'id_produto')

join_itens_pedido_df.show(5)

join_pedidos_entreges_df = pedidos.filter(col('status_pedido') == 'canceled').join(clientes,'id_cliente')

join_pedidos_entreges_df.show(5)

pedidos_concat_df = pedidos.withColumn('id_pedido_cliete', concat(col('id_pedido'), lit('-'),col('id_cliente')))

colunas = pedidos_concat_df.columns
print(colunas)

colunas.remove('id_pedido_cliete')
colunas.insert(0,'id_pedido_cliete')

pedidos_reogarnizar_df = pedidos_concat_df.select(colunas)

pedidos_reogarnizar_df.show(n = 5, truncate=False)

join_itens_pedido_df.write.mode('overwrite').option('header', 'true').parquet('drive/MyDrive/Spark/Data/output/join_itens_pedido_parquet')

spark.read.option('header','true').parquet('drive/MyDrive/Spark/Data/output/join_itens_pedido_parquet').show(5)

spark.stop()